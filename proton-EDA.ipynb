{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# DATASET FROM: http://archive.ics.uci.edu/ml/datasets/Online+Retail+II\n",
    "\n",
    "# GF TODO: check if excel present, otherwise download it\n",
    "# wget http://archive.ics.uci.edu/ml/machine-learning-databases/00502/online_retail_II.xlsx\n",
    "\n",
    "excel_with_path  = '/eos/user/f/franzoni/SWAN_projects/proton/online_retail_II.xlsx'\n",
    "pickle_with_path = '/eos/user/f/franzoni/SWAN_projects/proton/online_retail_II.pkl'\n",
    "csv_with_path = '/eos/user/f/franzoni/SWAN_projects/proton/online_retail_II.csv'\n",
    "\n",
    "df = None\n",
    "\n",
    "if os.path.isfile(pickle_with_path):\n",
    "    print('-> picke already exists, much faster using it than opening excel files\\n')\n",
    "    df = pd.read_pickle(pickle_with_path)\n",
    "else:\n",
    "    print('-> picke does not exist, go to excel, and create it\\n')\n",
    "    df1 = pd.read_excel (excel_with_path,'Year 2009-2010')\n",
    "    df2 = pd.read_excel (excel_with_path,'Year 2010-2011')\n",
    "    df = pd.concat([df1, df2])\n",
    "    df.to_pickle(pickle_with_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction'] = df.Quantity * df.Price\n",
    "df=df.rename(columns={\"Customer ID\": \"Customer_ID\"})\n",
    "\n",
    "from datetime import datetime\n",
    "df['InvoiceDay'] = df['InvoiceDate'].map(lambda p: p.date())\n",
    "df['InvoiceTime'] = df['InvoiceDate'].map(lambda p: p.time())\n",
    "df['InvoiceWeek'] = df['InvoiceDate'].map(lambda p: p.isocalendar()[1]+52*(p.year-2010))\n",
    "# avoide negative weeks and start counting from the first week of the dataset, which starts from 01/12/2009\n",
    "df['InvoiceWeek'] = df['InvoiceWeek']+3\n",
    "\n",
    "\n",
    "# GF TODO: there are nan \n",
    "# GF TODO: there are fields which are 'empty char', e.g. in the customer_id\n",
    "\n",
    "def is_cancellation(s):\n",
    "    if isinstance(s, int):\n",
    "        #print \"ordinary invoice\"\n",
    "        return 0\n",
    "    elif isinstance(s, unicode):\n",
    "        #print \"unicode string\"\n",
    "        if s.rfind('C')!=-1:\n",
    "            return 1\n",
    "        else:\n",
    "            # print \"Something unexpected\"  # found, e.g. A506401\n",
    "            # print s\n",
    "            return 2\n",
    "\n",
    "df['IsCancellation'] = df['Invoice'].map(is_cancellation)        \n",
    "# df.to_csv(csv_with_path, encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[ (    isinstance(df.Invoice, (int, long)) ==True     ) ]\n",
    "\n",
    "df.loc[ df.Quantity < 0 ].iloc[0].Invoice\n",
    "iiii=df.loc[ df.Quantity < 0 ].iloc[0].Invoice\n",
    "type(iiii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii.rfind('C')!=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cancellation(s):\n",
    "    if isinstance(s, int):\n",
    "        #print \"ordinary invoice\"\n",
    "        return 0\n",
    "    elif isinstance(s, unicode):\n",
    "        #print \"unicode string\"\n",
    "        if s.rfind('C')!=-1:\n",
    "            return 1\n",
    "        else:\n",
    "            # print \"Something unexpected\"  # found, e.g. A506401\n",
    "            # print s\n",
    "            return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsCancellation'] = df['Invoice'].map(is_cancellation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df.Quantity > 0 ].iloc[0].Invoice\n",
    "type(df.loc[ df.Quantity > 0 ].iloc[0].Invoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the nulls in each feature?\n",
    "nulls = df.isnull().sum()[df.isnull().sum() != 0]\n",
    "\n",
    "# select all transactions containing \n",
    "df_nulls = df[df.isnull().any(axis=1)].copy(deep=True)\n",
    "\n",
    "nulls_rel = nulls/df.shape[0]*100\n",
    "\n",
    "nulls_summary = pd.concat([nulls, nulls_rel], axis=1, keys=['nulls', 'rel. nulls [%]'])\\\n",
    "               .sort_values('nulls', ascending=False)\n",
    "\n",
    "nulls_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todo\n",
    "- nan and empty -> cleanup   # IN THE MAKING -> only consequences on the users study\n",
    "- add colums for data and time, separately ?    # DONE\n",
    "- create a second DF by user: RFM added to\n",
    "\n",
    "\n",
    "## What do I want to extract from this dataset?\n",
    "- https://en.wikipedia.org/wiki/Exploratory_data_analysis\n",
    "\n",
    "- how many customers   DONE\n",
    "- make a pliot of transaction, of purchase prices, and of invoice_price! #  DONE\n",
    "\n",
    "- VS TIME: trends of spending overall, by country\n",
    "- revenue as a function of date, as a function of the time in the day  # DONE\n",
    "- trends of spending: overall, by the largest customer, by the smaller customers (TOO SPECIFIC?)\n",
    "\n",
    "- NEED TO BUILD A PER CUSTOMER DF\n",
    "- customer: how many transactions, how much total revenue:\n",
    "    => BREAK DOWN BY country, tra\n",
    "- RMF\n",
    "\n",
    "\n",
    "- ==> do this\n",
    "- how many different types of items\n",
    "- what kind of items are bought the most (by NUMBER of by REVENUE), are cancelled the most, \n",
    "- how much revenue per type of item bought\n",
    "\n",
    "- correlation between\n",
    "- cancellations: fraction of cancellation by nunber of transactions and by proportion of renenue\n",
    "-                correlation to CHURNING ? Correlation to country OR type of good purchased ?\n",
    "\n",
    "- cust.groupby('customer_unique_id').size().value_counts() => The majority of customers made only a single purchase. # DONE\n",
    "\n",
    "\n",
    "- Can I cathegorise the purchasable items? => If so, customers split across those cathegories\n",
    "- Persona; how many cheap items, few expensive ones?\n",
    "- https://cxl.com/blog/creating-customer-personas-using-data-driven-research/\n",
    "- now many items are bought per session, how much is spent per session\n",
    "\n",
    "==> TOWARDS CUSTOMER PERSONA DEFINITION\n",
    "- MANY TRANSACTIONS ARE RECORDED AT THE SAME TIME => as if they were a single shopping session, but billed in split goups of goods\n",
    "- the function summary_data_from_transaction_data treats transactions taking place on the same day as A SINGLE ONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude cancellations to get the spectrum of single items price\n",
    "# motivation: the cancellation would give rise to a double counting\n",
    "\n",
    "# NOTE: cancellations are sometimes negative Quantity for positive price,\n",
    "# other times they are positive Quantity and negative price\n",
    "tit='Unit Price'\n",
    "(df.loc[ (df.Price > 0.) & (df.Quantity > 0)]).Price.plot(kind='hist',logy=True,title=tit,bins=50,figsize=(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative logic: account for cancelled items, as if they were normal purchases\n",
    "tit='Unit Price '\n",
    "df['Price'].map(lambda p: abs(p)) \\\n",
    "           .plot(kind='hist',logy=True,title=tit,bins=50,figsize=(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the transactions above 15k punds???\n",
    "df.loc[ (df.Price > 10000) & (df.Quantity > 0) ].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ (df.Price > 10000) & (df.Quantity < 0) ].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit='Transaction'\n",
    "df['Transaction'].plot(kind='hist',logy=True,title=tit,bins=100,figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit='Transaction'\n",
    "df.loc[ (df.Transaction >0) ].Transaction.plot(kind='hist',logy=True,title=tit,bins=100,range=(0,15000),figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit='Invoice'\n",
    "df.groupby('Invoice').Transaction.agg([sum])    \\\n",
    "   .rename(columns={\"sum\": \"rev_invoice\"})            \\\n",
    "   .sort_values(by=['rev_invoice'],ascending=False)  \\\n",
    "   .plot(kind='hist',logy=True,title=tit,bins=100,range=(0,200000),figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit='Invoice'\n",
    "df.groupby('Invoice').Transaction.agg([sum])    \\\n",
    "   .rename(columns={\"sum\": \"rev_invoice\"})            \\\n",
    "   .sort_values(by=['rev_invoice'],ascending=False)  \\\n",
    "   .plot(kind='hist',logy=True,title=tit,bins=100,range=(0,60000),figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d unique customers'%len(df.Customer_ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Customers are from %d countries'%len(df.Country.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I consider here only transactions with positive proceeds\n",
    "\n",
    "transaction_plus   = (df.loc[df.Transaction > 0.]).Transaction.agg([sum])\n",
    "transaction_cancel = (df.loc[df.Transaction < 0.]).Transaction.agg([sum])\n",
    "print('The total cash intake is %e pounds,\\n the total amount from cancellations is %e (%f )' \\\n",
    "        %(transaction_plus,transaction_cancel,-100*transaction_cancel/transaction_plus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toggle between the whole dataset (df) and the transactions w/ Customer_ID=Nan \n",
    "# to check for biases\n",
    "UU = df\n",
    "\n",
    "Cust_vs_country = UU.groupby('Country').Customer_ID.unique().agg([len])     \\\n",
    "                    .rename(columns={\"len\": \"num_customers\"})               \\\n",
    "                    .sort_values(by=['num_customers'],ascending=False)\n",
    "\n",
    "# I consider here only transactions with positive proceeds\n",
    "# I'll make a dedicated plot/column here below for negative/cancelled goods\n",
    "Revenue_vs_country = (UU.loc[UU.Transaction > 0.])                        \\\n",
    "                     .groupby('Country').Transaction.agg([sum])           \\\n",
    "                    .rename(columns={\"sum\": \"revenue\"})                     \\\n",
    "                    .sort_values(by=['revenue'],ascending=False)\n",
    "\n",
    "Cancellation_vs_country = (UU.loc[UU.Transaction < 0.])                \\\n",
    "                          .groupby('Country').Transaction.agg([sum])    \\\n",
    "                          .rename(columns={\"sum\": \"cancellation\"})            \\\n",
    "                          .sort_values(by=['cancellation'],ascending=False)\n",
    "\n",
    "# I chose to count ANY item listed, be it purchased or cancelled\n",
    "Items_vs_country = UU.groupby('Country').Invoice.agg([len])    \\\n",
    "                    .rename(columns={\"len\": \"num_items\"})            \\\n",
    "                    .sort_values(by=['num_items'],ascending=False)\n",
    "\n",
    "# I chose to count ANY item listed, be it purchased or cancelled\n",
    "Invoices_vs_country = UU.groupby('Country').Invoice.unique().agg([len])    \\\n",
    "                    .rename(columns={\"len\": \"num_invoices\"})            \\\n",
    "                    .sort_values(by=['num_invoices'],ascending=False)\n",
    "\n",
    "NoCustomerID_vs_country = df[df.isnull().any(axis=1)]                \\\n",
    "                    .groupby('Country').Transaction.agg([sum])     \\\n",
    "                    .rename(columns={\"sum\": \"no_customer_id\"})            \\\n",
    "                    .sort_values(by=['no_customer_id'],ascending=False) \\\n",
    "\n",
    "df_vs_country = Cust_vs_country              \\\n",
    "                .join(Revenue_vs_country )    \\\n",
    "                .join(Cancellation_vs_country)    \\\n",
    "                .join(Items_vs_country)   \\\n",
    "                .join(Invoices_vs_country)   \\\n",
    "                .join(NoCustomerID_vs_country,how='outer')   \\\n",
    "                .fillna(0)                                  \\\n",
    "                .sort_values(by=['revenue'],ascending=False) \\\n",
    "\n",
    "df_vs_country['rel_cancellation']   = \\\n",
    "           -100*df_vs_country['cancellation']/df_vs_country['revenue']\n",
    "\n",
    "df_vs_country['rel_no_customer_id'] = \\\n",
    "            100*df_vs_country['no_customer_id']/df_vs_country['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoCustomerID_vs_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vs_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.w3resource.com/pandas/dataframe/dataframe-plot-bar.php\n",
    "# good reference for plotting directly from pandas (less code!)\n",
    "df_vs_country.plot.pie(y='num_customers', figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= df_vs_country.drop(['cancellation','no_customer_id'], axis=1)  \\\n",
    "    .plot.bar(rot=90,figsize=(15,15),logy=True,fontsize=20,subplots=True)\n",
    "\n",
    "ax[0].set(ylabel = 'num. customers')\n",
    "ax[1].set(ylabel = 'revenue')\n",
    "ax[2].set(ylabel = 'num. items sold')\n",
    "ax[3].set(ylabel = 'num. invoices')\n",
    "ax[4].set(ylabel = 'canc. revenue [%]')\n",
    "# ax[4].set_yscale('linear')\n",
    "ax[5].set(ylabel = 'no_cus_id. revenue [%]')\n",
    "#ax[5].set_yscale('linear')\n",
    "\n",
    "for v in range(5):\n",
    "    ax[v].yaxis.get_label().set_fontsize(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('InvoiceDay').Transaction.agg(sum).plot(figsize=(25, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('InvoiceTime').Transaction.agg(sum).plot(figsize=(25, 3))  # must be limited to >0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('InvoiceWeek').Transaction.agg(sum).plot(figsize=(25, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the largest customer by total net revenue (i.e. taking into account also cancellations, in negative)\n",
    "# is in the UK and has ID 18102.0 and has purchased for 600k pounds\n",
    "df.groupby('Customer_ID').Transaction.agg([sum,min,max,len])                                                  \\\n",
    "        .rename(columns={'sum': 'Total Customer Revenue',                                                     \\\n",
    "                         'min': 'Min Transaction','max': 'Max Transaction',                                   \\\n",
    "                            'len' : 'Number of Transaction'})                                                 \\\n",
    "              .sort_values(by=['Total Customer Revenue'],ascending=False).head(10)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the customer with the largest number of transactions is \n",
    "# is in the UK, has ID 17841.0 and has carried out 13.1k transactions\n",
    "df.groupby('Customer_ID').Transaction.agg([sum,min,max,len])                                                  \\\n",
    "        .rename(columns={'sum': 'Total Customer Revenue',                                                     \\\n",
    "                         'min': 'Min Transaction','max': 'Max Transaction',                                   \\\n",
    "                            'len' : 'Number of Transaction'})                                                 \\\n",
    "              .sort_values(by=['Number of Transaction'],ascending=False).head(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the customer with the largest number of transactions is \n",
    "# is in the UK, has ID 17841.0 and has carried out 12.9 transactions (excluding cancellation transactions)\n",
    "df.loc[df.Transaction>0]                                                                                      \\\n",
    "    .groupby('Customer_ID').Transaction.agg([sum,min,max,len])                                                \\\n",
    "        .rename(columns={'sum': 'Total Customer Revenue',                                                     \\\n",
    "                         'min': 'Min Transaction','max': 'Max Transaction',                                   \\\n",
    "                            'len' : 'Number of Transaction'})                                                 \\\n",
    "              .sort_values(by=['Number of Transaction'],ascending=False).head(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the UK generates the largest revenue (16M over the two years),\n",
    "# surprisingly EIRE is the second largest source of revenue, with 0.6M (despite having only 6 customers, they must be huge customers)\n",
    "df.groupby('Country').Transaction.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Country').Transaction.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Customer_ID').size().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user lifetimes\n",
    "from lifetimes.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lifetimes.utils import *\n",
    "from lifetimes import BetaGeoFitter,GammaGammaFitter\n",
    "from lifetimes.plotting import plot_probability_alive_matrix, plot_frequency_recency_matrix, plot_period_transactions, plot_cumulative_transactions,plot_incremental_transactions\n",
    "from lifetimes.generate_data import beta_geometric_nbd_model\n",
    "from lifetimes.plotting import plot_calibration_purchases_vs_holdout_purchases, plot_period_transactions,plot_history_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pip install worked out fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
