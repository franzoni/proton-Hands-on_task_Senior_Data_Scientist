{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# GF TODO: check if excel present, otherwise download it\n",
    "# wget http://archive.ics.uci.edu/ml/machine-learning-databases/00502/online_retail_II.xlsx\n",
    "\n",
    "excel_with_path  = '/eos/user/f/franzoni/SWAN_projects/proton/online_retail_II.xlsx'\n",
    "pickle_with_path = '/eos/user/f/franzoni/SWAN_projects/proton/online_retail_II.pkl'\n",
    "csv_with_path = '/eos/user/f/franzoni/SWAN_projects/proton/online_retail_II.csv'\n",
    "\n",
    "df = None\n",
    "\n",
    "if os.path.isfile(pickle_with_path):\n",
    "    print('-> picke already exists, much faster\\n')\n",
    "    df = pd.read_pickle(pickle_with_path)\n",
    "else:\n",
    "    print('-> picke does not exist, go to excel, and create it\\n')\n",
    "    df1 = pd.read_excel (excel_with_path,'Year 2009-2010')\n",
    "    df2 = pd.read_excel (excel_with_path,'Year 2010-2011')\n",
    "    df = pd.concat([df1, df2])\n",
    "    df.to_pickle(pickle_with_path)\n",
    "\n",
    "df['Transaction'] = df.Quantity * df.Price\n",
    "df=df.rename(columns={\"Customer ID\": \"Customer_ID\"})\n",
    "\n",
    "# df.to_csv(csv_with_path, encoding = 'utf-8')\n",
    "\n",
    "# GF TODO: there are nan \n",
    "# GF TODO: there are fields which are 'empty char', e.g. in the customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I want to extract from this dataset?\n",
    "- https://en.wikipedia.org/wiki/Exploratory_data_analysis\n",
    "- how many customers\n",
    "- how many customer in which country\n",
    "- how much do customers spend => make a PLOT!\n",
    "- trends of spending: overall, by the largest customer, by the smaller customers\n",
    "\n",
    "- how many different types of items\n",
    "- what kind of items are bought the most (by NUMBER of by REVENUE), are cancelled the most, \n",
    "- how much revenue per type of item bought\n",
    "- correlation between \n",
    "\n",
    "- cust.groupby('customer_unique_id').size().value_counts() => The majority of customers made only a single purchase.\n",
    "\n",
    "\n",
    "##  Are there users at high risk of churning by the end of 2011\n",
    "\n",
    "- https://www.kdnuggets.com/2019/05/churn-prediction-machine-learning.html \n",
    "- https://towardsdatascience.com/hands-on-predict-customer-churn-5c2a42806266\n",
    "- https://www.google.com/search?q=dwarf+on+the+shoulders+of+giants&rlz=1C5CHFA_enCH771CH771&sxsrf=ALeKk034vLLmAHn5V1c0QAON4DZuO1GqVA:1582207255390&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiRrayrpeDnAhXCxaYKHZQVCgcQ_AUoAXoECBIQAw&biw=1418&bih=915#imgrc=oj4GwW0aHYfVYM\n",
    "- similar exercise resolved here https://towardsdatascience.com/modeling-customer-churn-for-an-e-commerce-business-with-python-874315e688bf\n",
    "- the repo of the library to be used https://github.com/CamDavidsonPilon/lifetimes\n",
    "- the reference paper in pdf http://brucehardie.com/papers/018/fader_et_al_mksc_05.pdf http://brucehardie.com/papers/bgnbd_2004-04-20.pdf and the journal which has all aspects of a respectable journals \n",
    "- GF TODO: once you've found which customers have churned, make a few hitory plots to prove that indeed they have churned, to show that I am not blindly trusing the package I've downloade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d unique customers'%len(df.Customer_ID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Customers are from %d countries'%len(df.Country.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GF can be removed\n",
    "# df.groupby('Country').Customer_ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('91 % of the customers are from the UK, 2% from Germany, 1.5% are from France. \\\n",
    " The remaining 40 countries have less than 1% of the customers')\n",
    "\n",
    "df.groupby('Country').Customer_ID.unique().agg([len])    \\\n",
    "    .rename(columns={\"len\": \"num_customers\"})            \\\n",
    "    .sort_values(by=['num_customers'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the largest customer by total net revenue (i.e. taking into account cancellations)\n",
    "# is in the UK and has ID 18102.0\n",
    "df.groupby('Customer_ID').Transaction.agg([sum,min,max,len])                                                  \\\n",
    "        .rename(columns={'sum': 'Total Customer Revenue',                                                     \\\n",
    "                         'min': 'Min Transaction','max': 'Max Transaction',                                   \\\n",
    "                            'len' : 'Number of Transaction'})                                                 \\\n",
    "              .sort_values(by=['Total Customer Revenue'],ascending=False).head(10)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Customer_ID').Transaction.agg([sum,min,max,len])                                                  \\\n",
    "        .rename(columns={'sum': 'Total Customer Revenue',                                                     \\\n",
    "                         'min': 'Min Transaction','max': 'Max Transaction',                                   \\\n",
    "                            'len' : 'Number of Transaction'})                                                 \\\n",
    "              .sort_values(by=['Number of Transaction'],ascending=False).head(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the customer with the largest number of transactions is \n",
    "# is in the UK and has ID 17841.0\n",
    "df.loc[df.Transaction>0]                                                                                      \\\n",
    "    .groupby('Customer_ID').Transaction.agg([sum,min,max,len])                                                \\\n",
    "        .rename(columns={'sum': 'Total Customer Revenue',                                                     \\\n",
    "                         'min': 'Min Transaction','max': 'Max Transaction',                                   \\\n",
    "                            'len' : 'Number of Transaction'})                                                 \\\n",
    "              .sort_values(by=['Number of Transaction'],ascending=False).head(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the UK generates the largest revenue (16M over the two years),\n",
    "# surprisingly EIRE is the second largest source of revenue, with 0.6M (despite having only 6 customers, they must be huge customers)\n",
    "df.groupby('Country').Transaction.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Country').Transaction.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user lifetimes\n",
    "from lifetimes.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lifetimes.utils import *\n",
    "from lifetimes import BetaGeoFitter,GammaGammaFitter\n",
    "from lifetimes.plotting import plot_probability_alive_matrix, plot_frequency_recency_matrix, plot_period_transactions, plot_cumulative_transactions,plot_incremental_transactions\n",
    "from lifetimes.generate_data import beta_geometric_nbd_model\n",
    "from lifetimes.plotting import plot_calibration_purchases_vs_holdout_purchases, plot_period_transactions,plot_history_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pip install worked out fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
